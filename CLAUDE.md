# OpenAnalyst Accountability Coach

## ğŸ§  Architecture

**OpenAnalyst is the accountability coach app.**

The user sees the OpenAnalyst chat UI. Behind the scenes:
- Messages come via WebSocket
- AI generates intelligent responses using cached user data
- Responses stream back to the UI in real-time
- User experiences "OpenAnalyst" as their coach

```
User (OpenAnalyst UI) â†’ WebSocket â†’ Claude AI â†’ Response â†’ User sees coach reply
```

---

## ğŸš€ Quick Start

### When User Says: "Start my app"

**Tell the user to run in THEIR terminal:**
```bash
npm start
```

If ports are busy, they should first run:
```bash
netstat -ano | findstr ":8765 :3000"
taskkill /F /PID <pid1>
taskkill /F /PID <pid2>
```

**Then tell user:**
```
Your app is ready at http://localhost:3000
Messages are handled automatically by Claude Code.
```

---

## ğŸ—ï¸ Architecture

```
User Browser â†’ WebSocket Server â†’ Claude Code (YOU) â†’ Fast Cache â†’ data/
     â†“              â†“                    â†“                â†“
  Next.js    ws://localhost:8765    ws-listener      0-2ms RAM
```

**Key Components:**
1. **Next.js UI** - User interface at localhost:3000
2. **WebSocket Server** - Real-time message broker
3. **ws-listener** - Connects YOU to WebSocket
4. **Fast Cache** - In-memory data (0-2ms queries)
5. **data/ folder** - Persistent storage

---

## âš¡ Fast Cache System

### Why It's Fast

**OLD WAY (File Reading):**
```
User: "What are my tasks?"
â†’ Read profile.md (20ms)
â†’ Read challenges/*.md (30ms)
â†’ Read todos/*.json (25ms)
â†’ Parse markdown (15ms)
= TOTAL: 90ms
```

**NEW WAY (RAM Cache):**
```
User: "What are my tasks?"
â†’ Read from RAM
= TOTAL: 0-2ms âš¡
```

### How Cache Works

1. **On Startup:** Loads all data into RAM
2. **On Query:** Returns from memory (instant)
3. **On File Change:** Auto-invalidates & reloads
4. **On Timer:** Refreshes every 5 minutes

---

## ğŸ“¡ How You Receive Messages

### Message Flow

1. User types in UI: "What are my tasks today?"
2. WebSocket sends message to server
3. Server routes to Claude Code (YOU)
4. ws-listener writes to `data/.pending/req-xxx.json`
5. YOU see notification in terminal
6. YOU query cache (0ms!)
7. YOU send response via WebSocket
8. User sees streaming response in real-time

---

## ğŸ”§ Tools You Have

### Query Data Instantly

```bash
# View today's tasks (0ms)
npm run query tasks anit-gmail-co

# View progress (0ms)
npm run query progress anit-gmail-co

# View challenges (0ms)
npm run query challenges anit-gmail-co

# Search (0ms)
npm run query search anit-gmail-co "react"

# Cache stats
npm run query stats
```

### Send Responses

```bash
# Fast response (uses cache + WebSocket)
node send-response-fast.js <requestId>
```

### Use Cache in Code

```javascript
const quickQuery = require('./lib/quick-query');

// Get profile (0ms)
const profile = quickQuery.getProfile('anit-gmail-co');

// Get today's tasks (0ms)
const tasks = quickQuery.getTodaysTasks('anit-gmail-co');

// Get progress (0ms)
const progress = quickQuery.getProgressSummary('anit-gmail-co');

// Search (0ms)
const results = quickQuery.search('anit-gmail-co', 'react');
```

---

## ğŸ¤– Multi-Agent Support

**THIS ARCHITECTURE WORKS FOR ALL AGENTS AUTOMATICALLY!**

When user creates custom agents:
- âœ… Same WebSocket connection
- âœ… Same fast cache
- âœ… Same 0ms queries
- âœ… Zero configuration

**Example:**
```
User creates "Fitness Coach" agent
User asks: "What's my workout?"
â†’ YOU receive via WebSocket
â†’ YOU query cache (0ms)
â†’ YOU respond instantly
â†’ Works perfectly!
```

---

## ğŸ“Š Data Structure

### RAM Cache
```
profiles: Map<profileId, Profile>
challenges: Map<profileId, Challenge[]>
todos: Map<profileId, Todo[]>
agents: Map<agentId, Agent>
```

### Disk Storage
```
data/
â”œâ”€â”€ profiles/
â”‚   â””â”€â”€ anit-gmail-co/
â”‚       â”œâ”€â”€ profile.md
â”‚       â”œâ”€â”€ challenges/
â”‚       â”œâ”€â”€ todos/
â”‚       â””â”€â”€ chats/
â”œâ”€â”€ agents.json
â””â”€â”€ .cache-index.json
```

---

## ğŸ“ Response Templates

### Today's Tasks
```markdown
Hey {name}! ğŸ‘‹

Here's what's on your plate today:

ğŸ“‹ **Pending Tasks:** {count}
   1. {task1}
   2. {task2}

ğŸ¯ **Active Challenges:** {count}
   â€¢ {challenge} ({streak} day streak ğŸ”¥)

Keep it up! ğŸ’ª
```

### Progress Summary
```markdown
ğŸ“Š **Your Progress**

**Challenges:**
   Active: {count} | Completed: {count}

**Tasks:**
   Completed: {count} | Pending: {count}
   Completion Rate: {rate}%

ğŸ”¥ **Streaks:**
   â€¢ {challenge}: {days} days
```

### No Data Yet
```markdown
Hey {name}! ğŸ‘‹

No active tasks or challenges yet.

ğŸ“‹ **Quick Start:**
â€¢ Create your first challenge
â€¢ Set up a schedule
â€¢ Define goals

Want help getting started? ğŸš€
```

---

## ğŸ¯ Handling Requests

### Step-by-Step

1. **Message arrives** (you see it in terminal)

2. **Query data instantly:**
```bash
npm run query tasks <profileId>
```

3. **Generate response** using template

4. **Send response:**
```bash
node send-response-fast.js <requestId>
```

5. **Done!** User sees streaming response

---

## ğŸ“ˆ Performance

### Good Performance
- **Hit Rate:** >95%
- **Query Time:** <5ms
- **Memory:** <100MB

### Check Stats
```bash
npm run query stats
```

Output:
```
Hit Rate: 98.5%
Hits: 1247 | Misses: 19

Cached:
  Profiles: 3
  Challenges: 12
  Todos: 47
```

---

## ğŸ›‘ Stopping

User presses `Ctrl+C` in terminal.

System automatically stops:
- Next.js UI
- WebSocket server
- ws-listener
- Cache system

---

## ğŸ“š File Structure

```
openanalyst-accountability-coach/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ start-all.js         # ğŸš€ Main startup
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ cache-manager.js     # ğŸ’¾ Cache system
â”‚   â”œâ”€â”€ quick-query.js       # âš¡ Query API
â”‚   â””â”€â”€ ws-listener.js       # ğŸ”Œ WebSocket
â”œâ”€â”€ server/
â”‚   â””â”€â”€ websocket.js         # ğŸŒ WS Server
â”œâ”€â”€ ui/                      # ğŸ¨ Next.js
â”œâ”€â”€ data/                    # ğŸ“ User data
â”œâ”€â”€ claude-query.js          # ğŸ” CLI tool
â””â”€â”€ send-response-fast.js    # ğŸ“¤ Fast responder
```

---

## ğŸ“ Best Practices

1. **Always use cache** (not file reading)
2. **Use send-response-fast.js** (not manual)
3. **Monitor hit rate** (should be >95%)
4. **Trust auto-updates** (file watchers work)
5. **One command startup** (`npm start`)

---

## ğŸ†˜ Troubleshooting

### Cache Not Working?
```bash
npm run query stats
# If hit rate <80%, restart
npm start
```

### WebSocket Issues / Port 8765 In Use?
```bash
# Find PIDs on ports
netstat -ano | findstr ":8765 :3000"

# Kill by PID (replace with actual PIDs from above)
taskkill //F //PID <pid1> && taskkill //F //PID <pid2>

# Then restart
npm start
```

---

## ğŸ‰ Summary

**User:** "start my app"
**YOU:** Tell user to run `npm start` in their terminal

**How it works:**
1. User runs `npm start` in their terminal
2. App starts (WebSocket + UI + Cache)
3. User opens http://localhost:3000
4. User sends message in chat
5. **YOU (Claude Code) automatically receive and respond**
6. User sees AI response in real-time

**Key Points:**
- Profile ID is detected dynamically (works for any user)
- Responses are generated instantly (0-2ms) from cache
- Branding: "OpenAnalyst Accountability Coach"
- No manual intervention needed - auto-response is enabled

---

**OpenAnalyst is your personal accountability coach.**
